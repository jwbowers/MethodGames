\documentclass[12pt]{article}
\usepackage{parskip}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{url}
\usepackage[pdftex,colorlinks=true,citecolor=black,raiselinks=false]{hyperref}
\usepackage{tgtermes}
\usepackage[T1]{fontenc}

\title{Method Games:\\ Assessing Methods for Discovery}
\author{Jake Bowers}
\date{\today}

\begin{document}
\maketitle

Imagine assessing a promising method for pattern discovery using a game.  One
scholar would invent a true pattern of features, generate an outcome and
perhaps hide this pattern amid irrelevant information.  For example, the game
designer might provide 15 binary features of 40 cases to the players. Players
would compete to discover the hidden truth.  One version of the method game
would require that participants use a particular algorithm. A second version
would allow participants to choose their own algorithm. For example, some
might choose a QCA variant \citep{rihoux2008configurational}, others would
implement an adaptive lasso \citep{zou2006adaptive} and still others might
prefer one of the many competitors to the lasso, such as the smoothly clipped
absolute deviation (SCAD) penalty \citep{fan2001variable}, random forests
~\citep{breiman2001random}, or kernel-regularized least squares
~\citep{hainmueller2012kernel}.)\footnote{\citet{hasttibfried09} provide an
  excellent overview of many of the techniques known as ``machine learning''
  or ``data mining''. The adaptive lasso and SCAD techniques used in this
  article belong to a family of machine learning algorithms known as penalized
  linear models. By setting coefficients to zero rather than privileging fit
  to data,  these procedures fit linear models to outcomes and aim to return
  coefficients of zero for irrelevant features and thereby revealing relevant
  features. Both choose coefficients $\beta_1, \ldots, \beta_P$ for $P$
  features (and arbitrary combinations thereof) to minimize a function of the
  sum of squared prediction error $\sum_{i=1}^N (y_i - ( \beta_0 + \beta_1 z_1
  + \ldots + \beta_P z_P) )^2$ plus a penalty function that rewards solutions
  with some (or many) $\beta_p$ set to 0. The adaptive lasso penalty is
  $\lambda \sum_{p=1}^P w_p|\beta_p|$ where $w_p=1/\hat{\beta}_p$ and
  $\hat{\beta}_p$ arises from a previous linear model (here a ridge regression
  but often an OLS regression). In this penalty function, the tuning
  parameter, $\lambda$, determines the importance of the sum of the absolute
  values of the coefficients in the total score. The SCAD replaces the lasso
  penalty with a function designed to have no penalty when $\beta_p=0$ (like
  the adaptive lasso) but then to rise smoothly to penalize very large
  $\beta_p$ less than the adaptive lasso penalty:
  $p_{\lambda}(\beta_p)=\begin{cases} \lambda |\beta_p|, & \text{if }
    |\beta_p|\le \lambda; \\ - \left( \frac{|\beta_p|^2 - 2 a \lambda
	|\beta_p| + \lambda^2}{2 (a-1)} \right), & \text{if } \lambda <
    |\beta_p| \le a \lambda; \\ \frac{(a+1)\lambda^2}{2},  & \text{if }
    |\beta_p| > a \lambda \end{cases}$, where $a > 2$ and $\lambda > 0$.
  Compared to the simple lasso penalty of $\lambda \sum_{p=1}^P |\beta_p|$,
  the SCAD penalty will label fewer features as irrelevant. The adaptive lasso
  is seen by some as an approximation or competitor to the SCAD penalty
  \cite[page 92]{hasttibfried09}. }
 
%%   \citet{fan2001variable} define the penalty by its derivative
%%   such that if the penalty function for a given $\beta$ is $p_\lambda(\beta)$ then
%%   $p'_{\lambda}(\beta)=\lambda \left\{ I(\beta \le \lambda) + \frac{ (a
%%       \lambda - \beta)_{+} }{ (a-1) \lambda} I(\beta > \lambda) \right\}$.    
%% }
%% 

In the first version of the competition, we would learn about craft: in
different hands the same method may perform differently. The results of this
competition would teach us about the judgment required to use the method
successfully.  In the version of the game where players choose different
approaches, we could learn how different methods compare in their ability to
address a given problem.\footnote{Although we might also confuse learning
  about method with a discovery that some researchers have excellent judgment
  and luck.}

If, however, time were short or players difficult to recruit, one could
approximate such a game by following standard practice in the machine learning
literature in the same way that \cite{lucasfk2014} among others have
investigated the performance of QCA. That is, a single scholar could generate a true relationship as if
kicking off a real method game but then write a computer program to compare
the effectiveness of different algorithms. Imagine that prior literature
suggests that two interactive patterns of features, $X_1, \ldots, X_P$, of a
given case $i$, drive outcomes (say, for $P=5$, $Y_i= (X_{i1} \cdot X_{i2}
\cdot X_{i3} ) \text{ OR } ( X_{i4} \cdot X_{i5} )$ where all $X_i  \in
\{0,1\}$ and thus $Y_i \in \{0,1\}$).  Further, imagine that three methods
suggest themselves as useful a priori: (1) QCA, (2) the adaptive lasso and (3)
iterative sure independence screening with a SCAD plugin (ISIS/SCAD)
\citep{fan2008sure}.  \citet{fan2001variable} proved that the SCAD penalty
would correctly set false parameters to 0 as $n \rightarrow \infty$ given a
reasonable choice of tuning parameters in contrast to the simple lasso
proposed by \cite{tibshirani1996regression}.  And \citet{fan2008sure} show
that, when the number of features is much larger than the number of cases, a
preliminary dimension reduction step improves the performance of the SCAD
penalty.  Later, \citet{zou2006adaptive} showed that a weighted version of the
lasso (known as the adaptive lasso) also has an oracle property conditional on
a well-chosen tuning parameter. Although QCA does not promise to find the
truth, it appears well suited to discovering complex comparisons and it does
not require tuning parameters.  This essay makes concrete such a machine
version of the method game using a script representing a situation where
substantive debate centers on a binary outcome and 40
cases.\footnote{Interested readers can download the code from
  \url{https://github.com/jwbowers/MethodGames}.}


Machine players are naive. Assessing the performance of a machine will not
tell us about the craft by which human scholars exploit a method.  Further,
any single collection of case attributes can idiosyncratically advantage one
method over another. For fairness, and to approximate the kind of natural
variation one would see if different human players were involved in the game,
the machine version of the method game script generated a different dataset
for each machine player.  Machine players are cheap, so this competition
involved 800 players each using all three approaches to seek the truth.  The
script runs two contests: The easier of the two games presents players with a
five column dataset: each column represents a part of the truth, and players
focus on finding the true interactions of the existing features.  The hard
game differs from the easy game only in that the data set contains 10
irrelevant case features in addition the original 5.  The script counts a
player as successful if it found the truth and only the truth. In the easy
game, QCA, the adaptive lasso, and ISIS/SCAD found the truth for 18\%, 82\%,
and 96\% of the players respectively. In the hard game, QCA, the adaptive
lasso, and ISIS/SCAD found the truth for 0\%, 33\%, and 61\% of the players
respectively.

These results do not suggest that we should discard QCA and the adaptive lasso
in favor of ISIS/SCAD.  A large and growing literature both criticizes and
builds on the adaptive lasso. For example, if the features are highly
intercorrelated, we might prefer adaptive versions of the fused lasso
\citep{rinaldo2009properties}, the grouped lasso \citep{wang2008note}, or the
elastic net \citep{ghosh2011grouped, zou2004regression}. And future
methodology related to QCA might adapt insights from machine learning to
overcome current shortcomings or advise against the use of QCA for particular
designs and data.  Most scholars would also prefer a technique
that recovers the truth in a method game more than 60\% of the time, so one might
use these results to motivate work to improve the performance of the ISIS/SCAD
or to find a substitute. Obviously, a real competition with skilled human players
with excellent judgment might have produced different results.  After all,
those who play with the script will notice little expertise and craft in use
of the techniques: for example, the tuning parameters for the adaptive lasso
were chosen fairly naively, only one open-source implementation of QCA was
used, and many other small but potentially consequential decisions appear
throughout.  The script does not display expert or even correct craft with any
of the three techniques.  Rather, the script shows how one may, in principle,
specify and run a machine version of the method game.

Fruitful communication about methods involves comparison --- of the successes
of different methods in the hands of different human scholars confronting
specific research designs, theoretical goals, and existing observations. The
method game proposed here would enable us to learn not only about a method in
an abstract sense, but about the craft of using said method in comparison with
other methods. A machine version of the method game enables a fast and cheap
and controlled way to begin to build a comparative understanding of the
methods and/or to motivate people to engage the fun of a real but
consequential game.



\bibliographystyle{apsr}
\bibliography{/Users/jwbowers/Documents/PROJECTS/BIB/big}
\end{document}


[^2]: 
